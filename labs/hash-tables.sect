<section id="hash-tables"><title>Lab: Hash Tables</title>

<para>
  <emphasis>Summary:</emphasis> In this laboratory, you will explore
  the wonder of hash tables.
</para>

<section id="hash-tables-prep"><title>Preparation</title>

<para>
  Fork and clone the repository at
  <ulink url="https://github.com/Grinnell-CSC207/hashtables"/>.
</para>

<para>
  Scan through the code so that you understand what methods are
  available and what approaches are used.  Make notes on areas
  that are likely to be problematic.
</para>

</section> <!-- hash-tables-prep -->

<section id="hash-tables-exercises"><title>Exercises</title>

<section id="hash-tables-01"><title>Exercise 1: Duplicate Keys</title>

<para>
  As you may have noted, the code for <methodname>set</methodname> does
  not check to see if the key is already being used.  The introductory
  notes therefore observe that this is a potential bug that should be
  fixed.
</para>

<para>
  a. Why is the failure to check whether the key is already used a 
  potential bug?  What effect might that failure to check have on the
  behavior of the program?
</para>

<para>
  b. Fill in the body of <methodname>repeatedSetExpt</methodname> with
  some experiments that help you see this effect.  
</para>

<para>
  c. If you'd like, you can start with my simple set of experiments.
</para>

<programlisting>
<xi:include href="../git/hashtables/src/taojava/util/repeatedSetExpt.txt" parse="text" xmlns:xi="http://www.w3.org/2001/XInclude"
/></programlisting>

<para> 
  d. Correct the bug.
</para>

</section> <!-- hash-tables-01 -->

<section id="hash-tables-02"><title>Exercise 2: Verifying that Keys Match</title>

<para>
  As you may have noted, the code assumes that <methodname>find</methodname>
  returns a cell with a matching key.  
</para>

<para>
  a. Is that the case?  Why or why not?
</para>

<para>
  b. In <filename>HashTableExpt</filename>, uncomment the call to 
  <methodname>matchingKeysExpt</methodname> to see what happens when
  two keys hash to the same location.
</para>

<para>
  c. Squash that second bug by updating <methodname>get</methodname>
  to check whether the key in the given cell matches the expected key.
</para>

</section> <!-- hash-tables-02 -->

<section id="hash-tables-03"><title>Exercise 3: Handling Collisions</title>

<para>
  As you may have noted, the code makes no attempt to deal with
  collisions.  Hey, it's even in the <quote>bugs to squash</quote>
  section.  (And, in some cases, you may have been tempted to fix
  the bug in a previous exercise.)
</para>

<para>
  a. Uncomment the call to <methodname>setExpt</methodname> so that
  you can see other potential effects of the unimplemented collision 
  detection.
</para>

<para>
  b. Update <methodname>find</methodname> to use linear probing.  If
  the current cell is full, and the keys don't match, try the cell that
  is <code>PROBE_OFFSET</code> away from the current cells (modulo the
  capacity of the table).  For example, if the table capacity is 20, the hash
  code gives us position 3, and the offset is 6, you should look in
  positions 3, 9 (3 + 6), 15, 1 (21 mod 20), 7, ....  
</para>

</section> <!-- hash-tables-03 -->

<section id="hash-tables-04"><title>Exercise 4: Improving Collision Handling</title>

<para>
  Here's a subtle bug that many programmers miss: For some combinations of
  table capacity and offset, we may cycle back before we've looked at every
  cell in the table.  For example, if the table capacity is 20, the hash code
  gives us position 3, and the offset is 5, we would look in positions
  3, 8, 13, 18, 3 (23 mod 20), 8, 13, 18, ....  So, even if the table is
  only 20% full, we might miss the empty cells.
</para>

<para>
  How do we fix this problem?  There are at least three approaches.
</para>

<itemizedlist>
   <listitem>
     We can choose a different offset after we cycle back to the
     beginning.  In this case, an offset of 1 is reasonable, because it
     helps ensure that we check every cell in the table.
   </listitem>

   <listitem>
     We can expand the table and hope that the new capacity works better.
   </listitem>

   <listitem>
     When we build/expand the table, we can ensure that the capacity of 
     the table and the offset are relatively prime.
   </listitem>

   <listitem>
     We could choose a different technique for checking.  One such 
     technique is <emphasis>quadratic probing</emphasis>.  First we
     check 1 element away.  Then four elements away.  Then nine elements
     away.  And so on and so forth.  (This mechanism also spreads
     things out a bit, but may also cycle strangely.)
   </listitem>
</itemizedlist>

<para>
  Which do you prefer?  Be prepared to explain your decision.
</para>

<para>
  We'll come back and implement one of these choices later.
</para>


</section> <!-- hash-tables-04 -->

<section id="hash-tables-05"><title>Exercise 5: Expanding Hash Tables</title>

<para>
  As the previous exercise reminded us, at some point we have to figure out
  how to expand the table.  Most frequently, we expand the table when it
  reaches a certain percentage full. (That percentage is by 
  <code>LOAD_FACTOR</code> in the current implementation.)
</para>

<para>
  Here's a sketch of a technique some students use to expand the table.
  (It's a sketch, in part, because I haven't checked that the code 
  compiles correctly.)
</para>

<programlisting>
   newCapacity = this.pairs.length * 2 + random(20);
   // Create a new table of that capacity
   this.pairs = new Object[newCapacity];
   // Move all the values from the old table to their appropriate 
   // location in the new table.
   for (int i = 0; i &lt; old.length; i++) {
       this.pairs[i] = old[i];
   } // for
</programlisting>

<para>
  a. What do you think about this approach?  (Don't critique the failure
  to use <methodname>Arrays.copyElts</methodname>, or whatever it's called.)
</para>

<para>
  b. Try adding these lines to <methodname>expand</methodname> and
  resolve any syntax errors.  Shrink the initial capacity of the array a
  bit so that we know <methodname>expand</methodname> gets called.  Run the
  <methodname>setExpt</methodname> method to see whether this technique
  for expansion works successfully.
</para>

<para>
  c. Correct any errors that you've identified.
</para>

<para>
  d. You may have noted that one approach we came up with for the linear
  hashing cycle problem was to make sure that the table cpacity is not a
  multiple of the probe offset.  Update your code to ensure this result.
  (Since we've made the probe offset a prime, all you have to do is to
  make sure that the table capacity is not a multiple of the probe offset.)
</para>

</section> <!-- hash-tables-05 -->

<section id="hash-tables-06"><title>Exercise 6: Removing Elements</title>

<para>
  We're making good progress.  What's next?  We should add support for
  removing elements.  Unfortunately, as we've learned, removing elements
  is often the most difficult aspect of implementing data structures.
  So let's think a bit about how we might approach the problem.
</para>

<para>
  a. Write some experiments that allow us to see what happens when
  we remove elements.
</para>

<para>
  b. Here's one approach to removing elements: Find the index of the
  key/value pair.  Put a <code>null</code> there to mark it as unused.
  Decrement the size field.  
</para>

<para>
  What do you think about this approach?
</para>

<para>
  c. Implement the approach and see what happens.
</para>

<para>
  d. Hopefully, you've found that this is a dangerous approach, since
  it breaks important assumptions for linear probing.  Come up with an
  alternate approach and discuss it with your teacher or class mentor.
</para>

</section> <!-- hash-tables-06 -->

<section id="hash-tables-07"><title>Exercise 7: Checking for Keys</title>

<para>
  Let's take a short break from thinking about how to remove elements
  and consider another issue.  The <methodname>containsKey</methodname>
  method is implemented a bit strangely.
</para>

<para>
  a. Read the code for <methodname>containsKey</methodname>.
</para>

<para>
  b. Do you expect this approach to work?  Why or why not?
</para>

<para>
  c. Conduct a few experiments to check your conclusion.
</para>

<para>
  d. Rewrite <methodname>containsKey</methodname> to use a more
  sensible approach.
</para>

</section> <!-- hash-tables-07 -->

<section id="hash-tables-08"><title>Exercise 8: Removing Elements, Revisited</title>

<para>
  Here's a potentially better mechanism for removing elements: Find the
  index of the key/value pair.  Set the key to null.   Decrement the size
  field.
</para>

<para>
  This approach is likely to significantly affect the
  <methodname>find</methodname> method, which now has to skip over.
  the cell when searching. but should probably return the cell if the
  search fails.  Why?  Because we use <methodname>find</methodname>
  for two reasons: to look things up for <methodname>get</methodname>
  and <methodname>containsKey</methodname>, and to find an empty
  location for use with <methodname>set</methodname>.  For the
  observers, it's okay that we look until we reach the end.  However,
  for <methodname>set</methodname>, we really want to use the first
  available spot.
</para>

<para>
  Implement this approach, updating <methodname>find</methodname>,
  <methodname>set</methodname>, <methodname>get</methodname>, and anything
  else you deem appropriate.
</para>


</section> <!-- hash-tables-08 -->

</section> <!-- hash-tables-exercises -->

<section id="hash-tables-extra"><title>For Those With Extra Time</title>

<para>
  If you find that you have extra time, try any of the following
  problems.
</para>

<para>
  Implement an iterator over values.  Details forthcoming.
</para>

<para>
  Implement an iterator over keys.  Details forthcoming.
</para>

</section> <!-- hash-tables-extra -->

</section> <!-- hash-tables -->
